{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMtYfshSSws7YLwfD+96/1k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alvira-Parveen/multimodal-fake-news-/blob/main/multimodal_fake_news.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f-T1SCj1kXz",
        "outputId": "c39f126b-4fc1-4d20-fba6-9d5031048d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 29 15:41:21 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0             28W /   70W |     644MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Step 1 â€“ Setup (GPU + installs)\n",
        "\n",
        "!nvidia-smi   # check if GPU is available\n",
        "!pip install torch torchvision transformers tqdm scikit-learn pillow requests\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2 â€“ Mount Google Drive & unzip dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, zipfile\n",
        "\n",
        "ZIP_PATH = \"/content/drive/MyDrive/Dataset/weibo.zip\"\n",
        "BASE_DIR = \"/content/weibo\"\n",
        "\n",
        "if not os.path.exists(BASE_DIR):\n",
        "    print(\"Unzipping dataset...\")\n",
        "    with zipfile.ZipFile(ZIP_PATH, 'r') as z:\n",
        "        z.extractall(BASE_DIR)\n",
        "else:\n",
        "    print(\"Already extracted:\", BASE_DIR)\n",
        "\n",
        "!ls /content/weibo | head -20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVv1eMWLIZY1",
        "outputId": "4d0100d8-fcd0-48fc-ba3d-4c2640dc6d3c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Unzipping dataset...\n",
            "Description\n",
            "fake_news\n",
            "real_news\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3 â€“ Parse JSON files into DataFrame\n",
        "\n",
        "import json, pandas as pd\n",
        "\n",
        "rows = []\n",
        "for root, dirs, files in os.walk(BASE_DIR):\n",
        "    for f in files:\n",
        "        if f == \"new.json\":\n",
        "            label = 1 if \"fake_news\" in root else (0 if \"real_news\" in root else None)\n",
        "            if label is not None:\n",
        "                try:\n",
        "                    with open(os.path.join(root, f), \"r\", encoding=\"utf-8\") as fh:\n",
        "                        j = json.load(fh)\n",
        "                    text = (j.get(\"text_raw\") or j.get(\"text\") or \"\").strip()\n",
        "                    image_url = None\n",
        "                    pic_infos = j.get(\"pic_infos\", {})\n",
        "                    if isinstance(pic_infos, dict) and len(pic_infos) > 0:\n",
        "                        first = list(pic_infos.values())[0]\n",
        "                        for key in (\"original\",\"large\",\"bmiddle\",\"mw2000\"):\n",
        "                            if isinstance(first.get(key), dict) and \"url\" in first[key]:\n",
        "                                image_url = first[key][\"url\"]; break\n",
        "                    if text:\n",
        "                        rows.append([text, image_url, label])\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\"text\",\"image_url\",\"label\"])\n",
        "print(\"âœ… Parsed samples:\", len(df))\n",
        "print(df.head())\n",
        "print(df[\"label\"].value_counts())\n",
        "\n",
        "CLEAN_CSV = os.path.join(BASE_DIR, \"weibo_clean.csv\")\n",
        "df.to_csv(CLEAN_CSV, index=False)\n",
        "print(\"Saved clean dataset to\", CLEAN_CSV)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sguLO6MmIdwf",
        "outputId": "8566a165-c6cf-4640-c352-23b379f351fc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Parsed samples: 11329\n",
            "                                                text  \\\n",
            "0                                  æµæµªç‹— æµæµªçŒ«  æµæµªé¸¡â€¦ â€‹â€‹â€‹   \n",
            "1  #å®˜æ–¹å›žåº”çŽ›èŽŽæ‹‰è’‚å¥³å¸æœºé†‰é©¾æ‰¾å…³ç³»# å®˜æ–¹å›žåº”æ­£åœ¨æ ¸æŸ¥ï¼Œè€ç™¾å§“å…¶å®žæ›´æƒ³çŸ¥é“ï¼Œç½‘ä¼ çš„è¿™ä¿©äººï¼Œä¸€...   \n",
            "2                        #éŸ©å›½æ°‘ä¼—åœ¨æ±‰æ±Ÿæ‹åˆ°æ°´æ€ª#\\né‰´å®šä¸ºæŒ‚ä½çš„å¡‘æ–™ â€‹â€‹â€‹   \n",
            "3                               æˆ‘è¦åŽ» æˆ‘çŽ°åœ¨å°±æ”¶æ‹¾è¡ŒæŽ æ‹œæ‹œäº† â€‹â€‹â€‹   \n",
            "4  #é»Žå·´å«©é¦–éƒ½çªå‘çˆ†ç‚¸#å½“åœ°æ—¶é—´4æ—¥ï¼Œé»Žå·´å«©é¦–éƒ½å‘ç”Ÿçˆ†ç‚¸ï¼Œå¤©ç©ºå‡ºçŽ°è˜‘è‡äº‘ï¼Œæ­»äº¡äººæ•°è¾¾åˆ°ä¸Šåƒäººã€‚...   \n",
            "\n",
            "                                           image_url  label  \n",
            "0  https://wx3.sinaimg.cn/orj1080/006zt3X9gy1hdaz...      1  \n",
            "1  https://wx1.sinaimg.cn/orj1080/6dbbb365ly1gw9a...      1  \n",
            "2  https://wx2.sinaimg.cn/orj1080/006WjnFPly1h60m...      1  \n",
            "3  https://wx3.sinaimg.cn/orj1080/008pOE3Mly1h8bo...      1  \n",
            "4                                               None      1  \n",
            "label\n",
            "0    5668\n",
            "1    5661\n",
            "Name: count, dtype: int64\n",
            "Saved clean dataset to /content/weibo/weibo_clean.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4 â€“ Train / Test split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "    df, test_size=0.2, stratify=df[\"label\"], random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train samples:\", len(train_df))\n",
        "print(\"Test samples:\", len(test_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtviTOa7Ig03",
        "outputId": "d0423564-d8ab-44a7-c6c3-ffcf516406c5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 9063\n",
            "Test samples: 2266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5 â€“ Download images\n",
        "\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "IMAGES_DIR = \"/content/weibo_images\"\n",
        "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
        "\n",
        "session = requests.Session()\n",
        "session.headers.update({\"User-Agent\": \"Mozilla/5.0\"})\n",
        "\n",
        "def download_images(df, limit=None):\n",
        "    downloaded = 0\n",
        "    local_paths = []\n",
        "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        url = row[\"image_url\"]; local_path = None\n",
        "        if isinstance(url, str) and url.strip():\n",
        "            try:\n",
        "                local_path = os.path.join(IMAGES_DIR, f\"{i}.jpg\")\n",
        "                if not os.path.exists(local_path):\n",
        "                    resp = session.get(url, timeout=8)\n",
        "                    if resp.status_code == 200:\n",
        "                        with open(local_path, \"wb\") as fh:\n",
        "                            fh.write(resp.content)\n",
        "                if os.path.exists(local_path): downloaded += 1\n",
        "            except: local_path = None\n",
        "        local_paths.append(local_path)\n",
        "        if limit and downloaded >= limit: break\n",
        "    print(\"Downloaded:\", downloaded)\n",
        "    return local_paths\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "test_df  = test_df.reset_index(drop=True)\n",
        "\n",
        "train_df[\"image\"] = download_images(train_df, limit=2000)   # safe limit first run\n",
        "test_df[\"image\"]  = download_images(test_df, limit=500)\n",
        "\n",
        "train_df.to_csv(\"/content/train_with_images.csv\", index=False)\n",
        "test_df.to_csv(\"/content/test_with_images.csv\", index=False)\n",
        "print(\"âœ… Saved train/test datasets with local image paths\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtkDPpSXIksy",
        "outputId": "6a64be98-0cbc-4453-bfba-3fc50dfee3cc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9063/9063 [00:20<00:00, 452.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2266/2266 [00:04<00:00, 496.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: 0\n",
            "âœ… Saved train/test datasets with local image paths\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6 â€“ Dataset + DataLoader\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "MAX_LEN = 64\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"âœ… Using device:\", DEVICE)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "class WeiboDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, transform, max_length=64):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.transform = transform\n",
        "        self.max_length = max_length\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        text = str(row[\"text\"])\n",
        "        enc = self.tokenizer(text, padding=\"max_length\", truncation=True,\n",
        "                             max_length=self.max_length, return_tensors=\"pt\")\n",
        "        input_ids = enc[\"input_ids\"].squeeze(0)\n",
        "        attention_mask = enc[\"attention_mask\"].squeeze(0)\n",
        "        img_path = row.get(\"image\")\n",
        "        if isinstance(img_path, str) and os.path.exists(img_path):\n",
        "            img = Image.open(img_path).convert(\"RGB\"); image = self.transform(img)\n",
        "        else:\n",
        "            image = torch.zeros(3,224,224)\n",
        "        label = int(row[\"label\"])\n",
        "        return {\"input_ids\": input_ids,\"attention_mask\": attention_mask,\n",
        "                \"image\": image,\"label\": torch.tensor(label)}\n",
        "\n",
        "train_df = pd.read_csv(\"/content/train_with_images.csv\")\n",
        "test_df  = pd.read_csv(\"/content/test_with_images.csv\")\n",
        "\n",
        "train_ds = WeiboDataset(train_df, tokenizer, image_transform, max_length=MAX_LEN)\n",
        "test_ds  = WeiboDataset(test_df, tokenizer, image_transform, max_length=MAX_LEN)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "print(\"âœ… Batch shapes:\", batch[\"input_ids\"].shape, batch[\"image\"].shape, batch[\"label\"].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVKJTlgBInge",
        "outputId": "921e9f56-31fa-41cd-8a68-470961a7df8d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Using device: cuda\n",
            "âœ… Batch shapes: torch.Size([16, 64]) torch.Size([16, 3, 224, 224]) torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7 â€“ Define Multimodal Model (BERT + ResNet50 Fusion)\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from transformers import BertModel\n",
        "\n",
        "class MultimodalFakeNewsModel(nn.Module):\n",
        "    def __init__(self, text_model_name=\"bert-base-chinese\", num_labels=2):\n",
        "        super().__init__()\n",
        "        # Text Encoder\n",
        "        self.text_encoder = BertModel.from_pretrained(text_model_name)\n",
        "        text_dim = self.text_encoder.config.hidden_size  # 768 for base BERT\n",
        "\n",
        "        # Image Encoder (ResNet50 pretrained on ImageNet)\n",
        "        resnet = models.resnet50(pretrained=True)\n",
        "        resnet.fc = nn.Identity()   # remove final classifier\n",
        "        self.image_encoder = resnet\n",
        "        img_dim = 2048\n",
        "\n",
        "        # Projection layers\n",
        "        self.text_fc = nn.Linear(text_dim, 512)\n",
        "        self.img_fc = nn.Linear(img_dim, 512)\n",
        "\n",
        "        # Fusion classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 + 512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, num_labels)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, images):\n",
        "        # Text features\n",
        "        txt_out = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        txt_feat = txt_out.pooler_output if txt_out.pooler_output is not None else txt_out.last_hidden_state[:,0,:]\n",
        "        txt_feat = self.text_fc(txt_feat)\n",
        "\n",
        "        # Image features\n",
        "        img_feat = self.image_encoder(images)\n",
        "        img_feat = self.img_fc(img_feat)\n",
        "\n",
        "        # Fusion\n",
        "        fused = torch.cat([txt_feat, img_feat], dim=1)\n",
        "        logits = self.classifier(fused)\n",
        "        return logits\n",
        "\n",
        "# Init model\n",
        "model = MultimodalFakeNewsModel().to(DEVICE)\n",
        "print(\"âœ… Model ready on:\", DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQoesJ-7NYOK",
        "outputId": "302518cc-48a1-4cce-c075-2cbeb6adff05"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model ready on: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8 â€“ Training & Evaluation Functions\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    losses, preds_all, labels_all = [], [], []\n",
        "    for batch in tqdm(loader, desc=\"Train\"):\n",
        "        optimizer.zero_grad()\n",
        "        ids = batch[\"input_ids\"].to(device)\n",
        "        mask = batch[\"attention_mask\"].to(device)\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        logits = model(ids, mask, imgs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "        preds_all.extend(preds)\n",
        "        labels_all.extend(labels.cpu().numpy())\n",
        "    return np.mean(losses), accuracy_score(labels_all, preds_all), f1_score(labels_all, preds_all, average=\"macro\")\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    losses, preds_all, labels_all = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=\"Eval\"):\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            imgs = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            logits = model(ids, mask, imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            preds = logits.argmax(dim=1).cpu().numpy()\n",
        "            preds_all.extend(preds)\n",
        "            labels_all.extend(labels.cpu().numpy())\n",
        "    return np.mean(losses), accuracy_score(labels_all, preds_all), f1_score(labels_all, preds_all, average=\"macro\")\n"
      ],
      "metadata": {
        "id": "1CesHllLNb88"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9 â€“ Training Loop\n",
        "\n",
        "EPOCHS = 8   # keep small first, increase later\n",
        "best_val_f1 = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE)\n",
        "    val_loss, val_acc, val_f1 = evaluate(model, test_loader, criterion, DEVICE)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.3f}, F1: {train_f1:.3f} || \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.3f}, F1: {val_f1:.3f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        print(\"âœ… Saved new best model!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5qLBeUNNfRt",
        "outputId": "7fd95084-2702-4cc1-e554-5054165c8eed"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 567/567 [03:32<00:00,  2.67it/s]\n",
            "Eval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:16<00:00,  8.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8 | Train Loss: 0.0218, Acc: 0.991, F1: 0.991 || Val Loss: 0.2873, Acc: 0.929, F1: 0.929\n",
            "âœ… Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 567/567 [03:27<00:00,  2.74it/s]\n",
            "Eval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:16<00:00,  8.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/8 | Train Loss: 0.0128, Acc: 0.993, F1: 0.993 || Val Loss: 0.3506, Acc: 0.931, F1: 0.931\n",
            "âœ… Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 567/567 [03:27<00:00,  2.73it/s]\n",
            "Eval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:16<00:00,  8.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/8 | Train Loss: 0.0173, Acc: 0.992, F1: 0.992 || Val Loss: 0.3804, Acc: 0.927, F1: 0.927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 567/567 [03:26<00:00,  2.74it/s]\n",
            "Eval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:16<00:00,  8.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/8 | Train Loss: 0.0223, Acc: 0.990, F1: 0.990 || Val Loss: 0.3205, Acc: 0.923, F1: 0.923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 567/567 [03:26<00:00,  2.74it/s]\n",
            "Eval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:16<00:00,  8.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/8 | Train Loss: 0.0177, Acc: 0.992, F1: 0.992 || Val Loss: 0.3605, Acc: 0.920, F1: 0.920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 567/567 [03:26<00:00,  2.74it/s]\n",
            "Eval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:16<00:00,  8.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/8 | Train Loss: 0.0135, Acc: 0.993, F1: 0.993 || Val Loss: 0.3922, Acc: 0.930, F1: 0.930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 567/567 [03:26<00:00,  2.74it/s]\n",
            "Eval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:16<00:00,  8.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/8 | Train Loss: 0.0155, Acc: 0.992, F1: 0.992 || Val Loss: 0.4306, Acc: 0.924, F1: 0.924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 567/567 [03:26<00:00,  2.74it/s]\n",
            "Eval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:16<00:00,  8.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/8 | Train Loss: 0.0215, Acc: 0.992, F1: 0.992 || Val Loss: 0.3456, Acc: 0.931, F1: 0.931\n",
            "âœ… Saved new best model!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10 â€“ Inference Helper\n",
        "\n",
        "def infer(text, image_path=None):\n",
        "    model.eval()\n",
        "    enc = tokenizer(text, padding=\"max_length\", truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "    ids, mask = enc[\"input_ids\"].to(DEVICE), enc[\"attention_mask\"].to(DEVICE)\n",
        "\n",
        "    if image_path and os.path.exists(image_path):\n",
        "        img = Image.open(image_path).convert(\"RGB\")\n",
        "        img_tensor = image_transform(img).unsqueeze(0).to(DEVICE)\n",
        "    else:\n",
        "        img_tensor = torch.zeros(1,3,224,224).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(ids, mask, img_tensor)\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "        pred = int(np.argmax(probs))\n",
        "    return pred, probs\n",
        "\n",
        "# Test on one sample\n",
        "sample = test_df.sample(1).iloc[0]\n",
        "pred, probs = infer(sample[\"text\"], sample[\"image\"] if pd.notna(sample[\"image\"]) else None)\n",
        "print(\"True:\", sample[\"label\"], \"| Pred:\", pred, \"| Probs:\", probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP3tYSguNjcq",
        "outputId": "54a306d5-6ca0-43ee-f533-af0c1f609c50"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True: 1 | Pred: 1 | Probs: [1.0192944e-04 9.9989808e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix & Classification Report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ðŸ”¹ Evaluate on test set\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "model.eval()\n",
        "\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "        imgs = batch[\"image\"].to(DEVICE)\n",
        "        labels = batch[\"label\"].to(DEVICE)\n",
        "\n",
        "        logits = model(ids, mask, imgs)\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Classification report\n",
        "print(\"ðŸ“Š Classification Report:\\n\", classification_report(all_labels, all_preds, digits=4))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Real\", \"Fake\"],\n",
        "            yticklabels=[\"Real\", \"Fake\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "6pzDVPaJWgQp",
        "outputId": "1b8f687e-809a-4efd-9af3-b9e7ebe6f1ed"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9453    0.9145    0.9296      1134\n",
            "           1     0.9170    0.9470    0.9318      1132\n",
            "\n",
            "    accuracy                         0.9307      2266\n",
            "   macro avg     0.9312    0.9307    0.9307      2266\n",
            "weighted avg     0.9312    0.9307    0.9307      2266\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}